## **1. 神经网络训练torch.autograd** 

神经网络是一组数据处理函数的集合，这些函数由张量参数定义（权重、偏差)

训练有两个步骤：

- 前向传播 forward propagation:
- 后向传播backward propagation:

### **1.1. 神经网络训练案例：**

```python
import torch, torchvision
#使用预先训练好的模型，赋为model
model = torchvision.models.resnet18(pretrained=True)
#随机设定设置数据，一张3色彩频道、长宽64的图像，随机设定标签
data = torch.rand(1, 3, 64, 64)
labels = torch.rand(1, 1000)
```

### 1.2. 根据数据进行预测

即forward propagation

```
prediction = model(data) #forward pass
```

### 1.3. 根据预测和标签求损失函数

```
loss = (prediction - labels).sum()
loss.backward() #backward pass
```

### 1.4. 优化

```
optim = torch.optim.SGD(model.parameters(), lr = 1e-2, momentum = 0.9)
optim.step()
```

## **2. 定义神经网络**

### 2.1. 定义一个网络，名为`Net`

```python
import torch
import torch.nn as nn
import torch.nn.functional as F

class Net(nn.Module):
    
    #定义卷积层线性层
    def __init__(self, in_channels, out_channels, padding=1, kernel_size, stride=(1,1), bias=False):
        super(Net, self).__init__()
        #定义两个卷积层in_channels=1,out_channels=6,kernel=3
        self.conv1 = nn.Conv2d(1, 6, 3)
        self.conv2 = nn.Conv2d(6, 16, 3)
        #定义三个线性层
        self.fc1 = nn.Linear(16 * 6 * 6, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)
        
    #定义前向传播    
    def forward(self, x):
        #两卷积层之间增加池化层
        x = F.max_pool2d(F.relu(self.conv1(x)),(2,2))
        x = F.max_pool2d(F.relu(self.conv2(x)),2)
        #降维，行数-1为自由行，列数num_flatten_features,下面有定义.view规定行列数
        x = x.view(-1, self.num_flat_features(x)) 
        x = F.relu(self.fc1(X))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x
    #矩阵中的维度设置    
    def num_flat_features(self, x):
        size = x.size()[1:] #统计矩阵中的元素个数，从第1开始
        num_features = 1
        for s in size:
            num_features *= s
        return num_features
        
    net = Net()
    print(net)
```

### 2.2. 向所定义的`net=Net()`随机输入，并输出结果

```python
input = torch.randn(1,1,32,32)
out = net(input)
print(out)
```

+ 参数和反向传播梯度缓冲区归零，并随机填充

  ```python
  net.zero_grad()
  out.backward(torch.randn(1,10))
  ```

### 2.3. 计算损失函数

```
target = torch.randn(10)	#假定这是已知的标签
target = target.view(形状)	#将标签调整为与输出相同的形状
criterion = nn.MSEloss()	#MSEloss是nn中的损失函数

loss = criterion(output, target)
```

### 2.4. 优化更新权重

得到损失函数时，一般情况下要进行权重优化，以获得更好的损失函数

`weight = weight - learning_rate * gradient`

```python
learning_rate = 0.01
for f in net.parameters():
	f.data.sub_(f.grad.data *learning_rate)
```

已有的权重更新规则`SGD，Nesterov-SGD，Adam，RMSProp`

```python
import torch.optim as optim

#创建优化器，lr是learning_rate, net.parameters()直接调取参数
optimizer = optim.SGD(net.parameters(), lr = 0.01)
#排除优化器缓存的影响，归零
optimizer.zero_grad()
output = net(input)
loss = criterion(output, target)
loss.backward()
optimizer.step()
```

## 3. 结合数据案例：训练一分类器

数据集`CIFAR10` ，分类为`飞机`，`智能手机`，`鸟`，`猫`，`狗`等，图片3x32x32(3颜色通道，32x32像素)

### 3.1. 标准化加载数据集CIFAR10

```python
import torch
import torchvision
import torchvision.transform as transforms
```

归一化[-1,1]范围内的张量；导入数据

```python
transform = transforms.Compose
(
	[
     transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ]
)#Comepose将多个transforms打包一起，便于一同使用
trainset = torchvision.datasets.CIFAR10(root='./data', train=True, 
                                        download=True, transform=transform)#训练集
trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,
                                         shuffle=True, num_workers=2)
#DataLoader（样本集，每批处理量，是否洗牌上批结果，进程数）
testset = torchvision.datasets.CIFAR10(root='./data', train=False, 
                                       download=True, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=4,
                                        shuffle=False, num_workers=2)

classes = ('plane', 'car', 'bird', 'cat',
           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')
```

### 3.2. 展示训练的图片

```python
import matplotlib.pyplot as plt
import numpy as np

# functions to show an image


def imshow(img):
    img = img / 2 + 0.5     # unnormalize
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    plt.show()


# get some random training images
dataiter = iter(trainloader)
images, labels = dataiter.next()

# show images
imshow(torchvision.utils.make_grid(images))
# print labels
print(' '.join('%5s' % classes[labels[j]] for j in range(4)))
```

### 3.3. 定义一卷积神经网络

```python
import torch.nn as nn
import torch.nn.functional as F

class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(in_channels, out_channels, kernal)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.fc1 = nn.Linear(in_features, out_features, bias)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)
        
    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(-1, 16 * 5 * 5)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(X)
        return x
    
net = Net()
```

### 3.4. 损失函数与优化

```python
import torch.optim as optim

criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)
```

### 3.5. 训练网络

```python
for epoch in range(2):
    
    running_loss = 0.0
    for i, data in enumerate(trainloader, 0):
        # enumerate(trainloader, 0)从0开始，将trainloader枚举遍历并添加索引号，i是编号data数据。
        inputs, labels = data #data已经预先设定为[inputs, labels]列表
        #如果在GPU上，见4. 已经设定device，此句改为inputs, labels = data[0].to(device), data[1].to(device)
        
        optimizer.zero_grad() #优化器清零
        
        # 前向后向与优化
        outputs = net(inputs)        
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        
        # 打印数据
        running_loss += loss.item() #累加loss
        if i % 2000 == 1999: #每2000批输出
            print('[%d, %5d] loss: %.3f' %
                 (epoch + 1, i + 1, running_loss / 2000 )
                 )
            running_loss = 0.0
            
print('Finished Training')
```

### 3.6. 保存训练模型

```python
PATH = './cifar_net.pth' #.pth文件的路径
torch.save(net.state_dict(), PATH) 
#state_dict()是定义模型和优化后自动生成的可直接调用的字典映射，对应模型权重偏置等参数
```

### 3.7. 测试数据测试网络

参考3.3. 已经定义展示训练图片的函数，

```python
dataiter = iter(testloader)
images, labels = dataiter.next()

# print images
imshow(torchvision.utils.make_grid(images))
print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))
```

保存的训练模型路径在3.6. 中已经声明为变量`PATH`，加载此模型

```python
net = Net()
net.load_state_dict(torch.load(PATH))

output = net(images) #images已在展示图片中定义

_, predicted = torch.max(outputs, 1) #1代表张量outputs中每行的最大值，0是列的最大值
#此处net(images)中行最大值代表结果
print('Predicted:', ' '.join('%5s' % classes[predicted[j]]  #classes在加载数据集时已定义
                            for j in range(4)))
```

在整个网络上的结果：

```python
correct = 0
total = 0
with torch.no_grad():
    for data in testloader:
        images, labels = data
        outputs = net(images)
        _, predicted = torch.max(outputs.data, 1)
        
        # 测试样本数为所有的标签数量
        total += labels.size(0)
        # 当训练集上的预测与事先标注的标签相符，视为准确
        correct += (predicted == labels).sum().item()

print('Accuracy of the network on the 10000 test images: %d %%' % (
    100 * correct / total)) #求准确率
```

分类的预测结果

```python
lass_correct = list(0. for i in range(10)) #有10项标签分类
class_total = list(0. for i in range(10))
with torch.no_grad():
    for data in testloader:
        images, labels = data
        outputs = net(images)
        _, predicted = torch.max(outputs, 1)
        c = (predicted == labels).squeeze()
        for i in range(4):
            label = labels[i]
            class_correct[label] += c[i].item()
            class_total[label] += 1


for i in range(10):
    print('Accuracy of %5s : %2d %%' % (
        classes[i], 100 * class_correct[i] / class_total[i]))
```

## GPU上添加的语句

```python
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

# Assuming that we are on a CUDA machine, this should print a CUDA device:

print(device)

net.to(device)
inputs, labels = data[0].to(device), data[1].to(device)
```

这样设备号由变量device代替



下一章节https://pytorch.org/tutorials/beginner/pytorch_with_examples.html

